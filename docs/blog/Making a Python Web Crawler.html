<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="X-UA-Compatible" content="ie=edge"><!-- Bootstrap 3 --><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css"><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css"><link rel="stylesheet" href="../styles/css/external/github-markdown.css"><link rel="stylesheet" href="../styles/css/styles.css"><!--Font Awesome--><script src="https://use.fontawesome.com/80270d8f99.js"></script><script src="../js/marked.js"></script><style>.markdown-body {
                box-sizing: border-box;
                min-width: 200px;
                max-width: 980px;
                margin: 0 auto;
                padding: 45px;
            }

            @media (max-width: 767px) {
                .markdown-body {
                    padding: 15px;
                }
            }</style><title>Making a Python Web Crawler</title></head><body><!-- NAV BAR --><nav><div class="container"><ul class="nav-links"><li><a href="../index.html">ABOUT</a></li><li><a href="../resume.html">RESUME</a></li><li><a href="../portfolio.html">PORTFOLIO</a></li><li class="active"><a href="../blog.html">BLOG</a></li></ul><div class="menu" onclick="openNav()"><div class="bar"></div><div class="bar"></div><div class="bar"></div></div></div></nav><div id="mySidenav" class="sidenav"><a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a> <a href="../index.html">ABOUT</a> <a href="../resume.html">RESUME</a> <a href="../portfolio.html">PORTFOLIO</a> <a href="../blog.html">BLOG</a></div><article id="content" class="markdown-body"></article><footer><div class="container-fluid social-links"><div class="logos"><div class="row"><div class="col-xs-4"><a href="https://github.com/Banhawy" target="_blank"><img src="../img/github-logo.png" alt="github link"></a></div><div class="col-xs-4"><a href="https://www.linkedin.com/in/adham-banhawy/" target="_blank"><img src="../img/linkedin-logo.png" alt="linkdin link"></a></div><div class="col-xs-4"><a href="https://twitter.com/adham_benhawy" target="_blank"><img src="../img/twitter-logo.png" alt="twitter link"></a></div></div></div></div><div class="container-fluid footer"><div class="row"><div class="col-xs-6"><p>3131 Sumter Ave N, Crystal, 55427 MN</p></div><div class="col-xs-6"><p id="email">the.benhawy@ gmail.com</p></div></div></div></footer><script src="../js/jquery.min.js"></script><script src="../js/index.js"></script><script>document.getElementById('content').innerHTML=marked(`<a href="../blog.html">Back to Blog</a><br> 
 # Making a Python Web Crawler\nDisclaimer: I am by no means an advanced developer/programmer now and I definitely didn't know python at all when I started my internship. Just because you might not know python or never automated anything with code before doesn't mean it will take you years to learn how to. In fact it only took me a week or so to get the hang of it.\n![command line screenshot](../img/post2-0.png)\n## The Problem: A manual daily task and a weak memory\nPart of my job as a student intern developer is to provide occasional help to the marketing team in the office with analytics and data gathering.\nOne of those tasks is to check the university's main website's front page everyday to see if the featured article has changed. If so, I need to record the dates this article stayed up, take a screenshot, and record its title, description, and number of clicks it got in a google spreadsheet.\n\nThose are A LOT of steps not to mention having to remember to do that every single day when I have so many other tasks. Also, what if I checked one day before leaving work at 5:00 PM, and the article was updated at 5:05PM. I would notice the change only next morning and record down the incorrect date of removal.\n\nUp until 2 months ago, I did that routine and I was bad at it because some days I would forget to check and would have to check archive.org for a cached copy online. One day I decided I've had enough and decided to learn web crawling.\n\n## Web Crawling with Python and Beautiful Soup:\nPython is a really simple language that I managed to pick up in a week or two. You don't need to learn much except for the basic syntax, for loops, and importing libraries to start crawling the web. A good place to start is with this excellent book. (This links to the free online version)\nIn my case, I used a library called Beautiful Soup that basically takes an HTML page and breaks it down into one big dictionary you can traverse and change. If you want to learn more about how to use Beautiful Soup and go through a tutorial this post by Justin Yek is a great place to start.\nI first created a python file, named it homepage, and imported the libraries to be used:\n\`\`\`\nimport datetime\nimport urllib2\nfrom bs4 import BeautifulSoup\nimport unicodedata\n\`\`\`\nI use the datetime library to record and print the date and time the crawler/program is run:\n\`\`\` \n# Print Timestamp At time of crawl\ndatePosted = str(datetime.date.today())\nprint( 'Time of Crawl:  ' + datePosted)\n\`\`\`\nI then use the urllib2 library to get the HTML document of the front page, and use BeautifulSoup library to parse it:\n\`\`\`\n# Get page and parse its content\nurl =  'https://twin-cities.umn.edu/'\npage = urllib2.urlopen(url)\nsoup = BeautifulSoup(page,  'html.parser')\n\`\`\`\nNow I have the page's HTML in a nice dictionary so I can extract the featured article's url, image link, title, and so on.\nFrom inspecting the homepage in chrome dev tools, I find out that the featured article's image always has a class of either *mast__img* if it's a static image, or *mast__mobile* otherwise. (The otherwise happened when I found an error in the program's log one day not finding *mast__img*). I use BeatifulSoup's **.find()** method to target the article's image tag by its class:\n\`\`\`\n# In case the featured article has an image\nimageLinkText = soup.find( 'img', attrs={ 'class':  'mast__img'})\n# In case the featured article has a video\nvideoLinkText = soup.find('img', attrs={'class': 'mast__mobile'})\n\`\`\`\nNow the article's img tag is stored as an object in *imageLinkText/ videoLinkText*. Because I'm super lazy and I don't want to take a screenshot of the featured article as well, I will instead get the article's image link so I can access it even when a newer article is published. I use a similar technique to get that info, this time by targetting the image's src attribute:\n\`\`\`\n# Get Image link\ntry:\n   src = imageLinkText.get('src')\nexcept AttributeError:\n   src = videoLinkText.get('src')\nimageLink = unicodedata.normalize('NFKD', src).encode('ascii', 'ignore')\nprint('Image Link: \n' + imageLink)\n\`\`\`\nI need to normalize unicode data in src variable to remove umlauts, accents etc. For example "na&#239;ve caf&#233;	" would be changed to "naive cafe". I take this step to avoid any errors while printing out and storing ascii values.\n![screenshot of website's source page](../img/post2-1.png)\n\nNow to get the Article title and description I had to dig deep and be extra specific.\nI can't use **.find()** to get the class *mast__text* because that would return both the article title in the first p child as well as the description in the second p child. Instead I used BeautifulSoup's CSS selector method **.select()** which takes css selectors as its argument. In my case, I want the first p child of the class *.mast__text* so I choose **".mast__text p:nth-of-type(1)"**:\n\`\`\`\n# Get Article Title\narticleTitle = soup.select('.mast__text p:nth-of-type(1)')[0].text.strip().encode('ascii', 'ignore').strip()\nprint(title)\n\`\`\`\nThis will return an array of the matching elements. If the selector is specific enough it should return an array with one item. I convert the item from html code to text with **.text** and strip away white spaces with **.strip()** and store it in articleTitle variable.\nI use the same technique to get the article description:\n\`\`\`\n# Get Article description\narticleDescriptionList = soup.select('.mast__text p:nth-of-type(2)')\narticleDescription = articleDescriptionList[0].text.strip().encode('ascii', 'ignore').strip()\nprint('Article Description: \n' + articleDescription)\n\`\`\`\nFinally, I have the article link left to extract. Again I will use the css selector to get the first anchor tag within the featured article div given the class name *.node-promoted*:\n\`\`\`\n# Get Article Link\narticleLink = soup.select('.node-promoted a:nth-of-type(1)')\narticleLink = articleLink[0].get('href')\nprint('Article Link: \n' + articleLink)\n\`\`\`\n*soup.select( '.node-promoted a:nth-of-type(1)')* returns an array with first item as an html object:\n\`\`\` \n<a href="https://twin-cities.umn.edu/news-events/creating-countrys-identity" title="Learn more about Haider's art.">\n\`\`\` \n\nTo get the article's url I use **.get()** to get the value within the href attribute.\nPutting things together, the code should look like this:\n\`\`\`\nimport datetime\nimport urllib2\nfrom bs4 import BeautifulSoup\nimport unicodedata\n\n# Print Timestamp At time of crawl\ndatePosted = str(datetime.date.today())\nprint( 'Time of Crawl:  ' + datePosted)\n\n# Get page and parse its content\nurl =  'https://twin-cities.umn.edu/'\npage = urllib2.urlopen(url)\nsoup = BeautifulSoup(page,  'html.parser')\n\n# In case the featured article has an image\nimageLinkText = soup.find( 'img', attrs={ 'class':  'mast__img'})\n# In case the featured article has a video\nvideoLinkText = soup.find('img', attrs={'class': 'mast__mobile'})\n\n# Get Image link\ntry:\n   src = imageLinkText.get('src')\nexcept AttributeError:\n   src = videoLinkText.get('src')\nimageLink = unicodedata.normalize('NFKD', src).encode('ascii', 'ignore')\nprint('Image Link: \n' + imageLink)\n\n# Get Article Title\narticleTitle = soup.select('.mast__text p:nth-of-type(1)')[0].text.strip().encode('ascii', 'ignore').strip()\nprint(title)\n\n# Get Article description\narticleDescriptionList = soup.select('.mast__text p:nth-of-type(2)')\narticleDescription = articleDescriptionList[0].text.strip().encode('ascii', 'ignore').strip()\nprint('Article Description: \n' + articleDescription)\n\n# Get Article Link\narticleLink = soup.select('.node-promoted a:nth-of-type(1)')\narticleLink = articleLink[0].get('href')\nprint('Article Link: \n' + articleLink)\n\`\`\`\nThe output when run from the command line should look like this:\n![command line screenshot](../img/post2-2.png)\n\nVoila! That's the first useful web crawler I wrote and I depend on it till today. Of course the first version wasn't perfect, and the try/catch blocks are the results of uncaught errors some days, and even when writing this post I managed to optimize it a bit more.\n\nThis program alone would have been enough for me to cut the time I spent on this task from 10-15 minutes to 3-5 minutes when using the crawler. That's what I did for a few days until I gave the program more features and hooked it up to a google spreadsheet to keep a log online. However, this is a topic for a later post.`);</script></body></html>